{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8u0WV4ogId7ZzmRRMCcun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcoscleytton/simple-ml-regression/blob/main/rf_20features_gridsearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SyF0mbAJg5dH"
      },
      "outputs": [],
      "source": [
        "# import de bibliotecas\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split , GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criar a função do bags com mais features  informativas e intancias\n",
        "def create_bags (num_bags= 100, num_instances_per_bag= 20):\n",
        "    x, y = [],[]\n",
        "    num_positive_bags = num_bags // 2\n",
        "    num_negative_bags = num_bags - num_positive_bags\n",
        "\n",
        "\n",
        "    for _ in range(num_positive_bags):\n",
        "        # aqui vamos aumentar o numero de features e torna mais informativa\n",
        "        bag = make_classification(n_samples=num_instances_per_bag,n_features=20,n_informative=15)\n",
        "        x.append(bag[0])\n",
        "        y.append(1) # Assign label 1 for positive bags\n",
        "\n",
        "    for _ in range(num_negative_bags):\n",
        "        bag = make_classification(n_samples=num_instances_per_bag,n_features=20,n_informative=15)\n",
        "        x.append(bag[0])\n",
        "        y.append(0) # Assign label 0 for negative bags\n",
        "\n",
        "\n",
        "    return x, y\n",
        "\n",
        "# gerar as bags\n",
        "x, y = create_bags()\n",
        "\n",
        "# flatten dos dados para treinameno do modelo\n",
        "x_flat = np.array([instance for bag in x for instance in bag])\n",
        "y_flat = np.array([y[i] for i, bag in enumerate(x) for instance in bag])\n",
        "\n",
        "\n",
        "# dividir o conjunto de dados em treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_flat, y_flat, test_size=0.3, stratify=y_flat)\n",
        "\n",
        "# definir parametros para otimizalção com mais regularização\n",
        "param_grid = {\n",
        "    'n_estimators': [100], # mantemos 100 instimadores\n",
        "    'max_depth': [10],    # restrição de profundidade\n",
        "    'min_samples_split': [5, 10], # aumentar o criterio para divisão\n",
        "    'min_samples_leaf': [4, 6] # regularização adiocional\n",
        "}"
      ],
      "metadata": {
        "id": "3QEQq34ciaHc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gerar as bags\n",
        "x, y = create_bags()\n",
        "\n",
        "# flatten dos dados para treinameno do modelo\n",
        "x_flat = np.array([instance for bag in x for instance in bag])\n",
        "y_flat = np.array([y[i] for i, bag in enumerate(x) for instance in bag])\n",
        "\n",
        "\n",
        "# dividir o conjunto de dados em treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_flat, y_flat, test_size=0.3, stratify=y_flat)\n",
        "\n",
        "# definir parametros para otimizalção com mais regularização\n",
        "param_grid = {\n",
        "    'n_estimators': [100], # mantemos 100 instimadores\n",
        "    'max_depth': [10],    # restrição de profundidade\n",
        "    'min_samples_split': [5, 10], # aumentar o criterio para divisão\n",
        "    'min_samples_leaf': [4, 6] # regularização adiocional\n",
        "}"
      ],
      "metadata": {
        "id": "Tl8cS_8aj--i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar o gridsearchCV\n",
        "\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# melhor modelo encontrado pelo gridsearchCV\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# fazer previsão com melhor modelo\n",
        "y_pred = best_model.predict(x_test)"
      ],
      "metadata": {
        "id": "g-FWUR6onITf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# avaliar  a acuracia do modelo random forest otimizado\n",
        "\n",
        "accuracy_best_rf = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia do modelo random forest otimizado: {accuracy_best_rf:.2f}')\n",
        "\n",
        "# avaliar o modelo otimizado com roc & auc\n",
        "\n",
        "roc_score_best_rf = roc_auc_score(y_test, best_model.predict_proba(x_test)[:, 1])\n",
        "print(f'ROC AUC do modelo random forest otimizado: {roc_score_best_rf:.2f}')\n",
        "\n",
        "# testar o gradient boosting\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# treinar o modelo gradient boosting\n",
        "\n",
        "model_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=42)\n",
        "model_gb.fit(x_train, y_train)\n",
        "\n",
        "# fazendo predições com radient boosting\n",
        "\n",
        "y_pred_gb = model_gb.predict(x_test)\n",
        "\n",
        "# avaliar a acuracia e roc auc do gradient boosting\n",
        "\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "roc_score_gb = roc_auc_score(y_test, model_gb.predict_proba(x_test)[:, 1])\n",
        "\n",
        "print(f'Acurácia do modelo Gradient Boosting: {accuracy_gb:.2f}')\n",
        "print(f'ROC AUC do modelo Gradient Boosting: {roc_score_gb:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbtkn4Q3oBGb",
        "outputId": "70c5f831-83ae-4fc0-810a-8ed036e73ca9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo random forest otimizado: 0.57\n",
            "ROC AUC do modelo random forest otimizado: 0.57\n",
            "Acurácia do modelo Gradient Boosting: 0.57\n",
            "ROC AUC do modelo Gradient Boosting: 0.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testar o gradient\n",
        "\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "8h4H_sPiqd_J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinar modelo xboosting\n",
        "\n",
        "model_xgb = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=42)\n",
        "model_xgb.fit(x_train, y_train)\n",
        "\n",
        "# fazer previsão com xboosting\n",
        "\n",
        "y_pred_xgb = model_xgb.predict(x_test)\n",
        "\n",
        "# avaliar a acuracia roc auc do xboosting\n",
        "\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "roc_score_xgb = roc_auc_score(y_test, model_xgb.predict_proba(x_test)[:, 1])\n",
        "\n",
        "print(f'Acurácia do modelo XGBoost: {accuracy_xgb:.2f}')\n",
        "print(f'ROC AUC do modelo XGBoost: {roc_score_xgb:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8XAPjj8qonF",
        "outputId": "3aa34177-aa4e-42f6-c242-92cc12026230"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo XGBoost: 0.56\n",
            "ROC AUC do modelo XGBoost: 0.58\n"
          ]
        }
      ]
    }
  ]
}